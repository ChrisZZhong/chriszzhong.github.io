---
layout: post
title: "System Design - Robinhood"
date: 2025-12-17
description: ""
tag: System Design
prime: false
---

## Common Problems

Design Robinhood
================

Understanding the Problem
-------------------------

**ğŸ“ˆ What is [Robinhood](https://robinhood.com/)?** Robinhood is a commission-free trading platform for stocks, ETFs, options, and cryptocurrencies. It features real-time market data and basic order management. Robinhood isn't an exchange in its own right, but rather a stock broker; it routes trades through market makers ("exchanges") and is compensated by those exchanges via [payment for order flow](https://en.wikipedia.org/wiki/Payment_for_order_flow).

### Background: Financial Markets

There's some basic financial terms to understand before jumping into this design:

*   **Symbol**: An abbreviation used to uniquely identify a stock (e.g. META, AAPL). Also known as a "ticker".
    
*   **Order**: An order to buy or sell a stock. Can be a _market order_ or a _limit order_.
    
*   **Market Order**: An order to trigger immediate purchase or sale of a stock at the current market price. Has no price target and just specifies a number of shares.
    
*   **Limit Order**: An order to purchase or sell a stock at a specified price. Specifies a number of shares and a target price, and can sit on an exchange waiting to be filled or cancelled by the original creator of the order.
    

Outside of the above financial details, it's worth understanding the responsibilities of Robinhood as a business / system. **Robinhood is a brokerage and interfaces with external entities that actually manage order filling / cancellation.** This means that we're building a brokerage system that facilitates customer orders and provides a customer stock data. _We are not building an exchange._

For the purposes of this problem, we can assume Robinhood is interfacing with an "exchange" that has the following capabilities:

*   **Order Processing**: Synchronously places orders and cancels orders via request/response API.
    
*   **Trade Feed**: Offers subscribing to a trade feed for symbols. "Pushes" data to the client every time a trade occurs, including the symbol, price per share, number of shares, and the orderId.
    

For this interview, the interviewer is offering up an external API (the exchange) to aid in building the system. As a candidate, it's in your best interest to briefly clarify the exchange interface (APIs, both synchronous and asynchronous) so you have an idea of the tools at your disposal. Typically, the assumptions you make about the interface have broad consequences in your design, so it's a good idea to align with the interviewer on the details.

### [Functional Requirements](https://www.hellointerview.com/learn/system-design/in-a-hurry/delivery#1-functional-requirements)

**Core Requirements**

1.  Users can see live prices of stocks.
    
2.  Users can manage orders for stocks (market / limit orders, create / cancel orders).
    

**Below the line (out of scope)**

*   Users can trade outside of market hours.
    
*   Users can trade ETFs, options, crypto.
    
*   Users can see the [order book](https://www.investopedia.com/terms/o/order-book.asp) in real time.
    

This question focuses on stock viewing and ordering. It excludes advanced trading behaviors and doesn't primarily involve viewing historical stock or portfolio data. If you're unsure what features to focus on for a feature-rich app like Robinhood or similar, have some brief back and forth with the interviewer to figure out what part of the system they care the most about.

### [Non-Functional Requirements](https://www.hellointerview.com/learn/system-design/in-a-hurry/delivery#2-non-functional-requirements)

**Core Requirements**

1.  The system prefers high consistency for order management; it's _essential_ for users to see up-to-date order information when making trades.
    
2.  The system should scale to a high number of trades per day (20M daily active users, 5 trades per day on average, 1000s of symbols).
    
3.  The system should have low latency when reflecting symbol price updates and when placing orders (under 200ms).
    
4.  The system should minimize the number of active clients connecting to an external exchange API. Exchange data feeds / client connections are typically expensive.
    

**Below the line (out of scope)**

*   The system connects to multiple exchanges for stock trading.
    
*   The system manages trading fees / calculations (we can assume fees are not in scope).
    
*   The system enforces daily limits on trading behavior.
    
*   The system protects against bot usage.
    

Here's how it might look on a whiteboard:

Non-Functional Requirements

For this question, given the small number of functional requirements, the non-functional requirements are even more important to pin down. They characterize the complexity of these deceptively simple live price / order placement capabilities. Enumerating these challenges is important, as it will deeply affect your design.

The Set Up
----------

### Planning the Approach

Before you move on to designing the system, it's important to start by taking a moment to plan your strategy. Generally, we recommend building your design up sequentially, going one by one through your functional requirements. This will help you stay focused and ensure you don't get lost in the weeds as you go. Once you've satisfied the functional requirements, you'll rely on your non-functional requirements to guide you through the deep dives.

### [Defining the Core Entities](https://www.hellointerview.com/learn/system-design/in-a-hurry/delivery#core-entities-2-minutes)

Let's go through each high level entity. I like to do this upfront before diving into other aspects of the system so we have a list of concepts to refer back to when talking about the details of the system. At this stage, it isn't necessary to enumerate every column or detail. It's all about laying the foundation.

For Robinhood, the primary entities are pretty straightforward:

1.  **User**: A user of the system.
    
2.  **Symbol**: A stock being traded.
    
3.  **Order**: An order for a buy or sell, created by a user.
    

In the actual interview, this can be as simple as a short list like this. Just make sure you talk through the entities with your interviewer to ensure you are on the same page.

Core Entities

### [The API](https://www.hellointerview.com/learn/system-design/in-a-hurry/delivery#api-design-5-minutes)

The API is the primary interface that users will interact with. It's important to define the API early on, as it will guide your high-level design. We just need to define an endpoint for each of our functional requirements.

Let's start with an endpoint to get a symbol, which will include details and price data. We might have an endpoint like this:

    GET /symbol/:name
    Response: Symbol

To create an order, an endpoint might look like this:

    POST /order
    Request: {
      position: "buy",
      symbol: "META",
      priceInCents: 52210,
      numShares: 10
    }
    Response: Order

Note we're using priceInCents instead of price to avoid floating point precision issues. Especially for financial application it's better to use integers to avoid errors and [financial scams](https://screenrant.com/justice-league-incarnate-superman-iii-scheme-easter-egg).

To cancel an order, the endpoint could be as simple as:

    DELETE /order/:id
    Response: {
      ok: true
    }

Finally, to list orders for a user, the request could be:

    GET /orders
    Response: Order[] (paginated)

With each of these requests, the user information will be passed in the headers (either via session token or JWT). This is a common pattern for APIs and is a good way to ensure that the user is authenticated and authorized to perform the action while preserving security. You should avoid passing user information in the request body, as this can be easily manipulated by the client.

[High-Level Design](https://www.hellointerview.com/learn/system-design/in-a-hurry/delivery#high-level-design-10-15-minutes)
---------------------------------------------------------------------------------------------------------------------------

### 1) Users can see live prices of stocks

The first requirement of Robinhood is allowing users to see the live price of stocks. This might be one stock or many stocks, depending on what the user is viewing in the UI. To keep our design extensible, let's assume a user can see many live stock prices at once. To support this design, let's analyze a few options.

### 

Bad Solution: Polling Exchange Directly

##### Approach

This solution involves polling the exchange directly for price data per symbol. The client would poll every few seconds (per symbol), and update the price shown to the user based on the response.

##### Challenges

This is a simple approach that will not scale and will not minimize exchange client connections / calls. There's a few fundamental problems with this design:

*   **Redundant Exchange Calls**: This approach is a very inefficient way to get price information in terms of exchange call volume. It involves polling, which happens indiscriminately, even if the price has not changed. Additionally, it involves many clients requesting the same information from the exchange, which is wasteful. If 5000 clients are requesting a price at the same time, the price isn't different per client, yet we're expending 5000 calls (repeatedly) to disperse this information.
    
*   **Slow Updates**: If we're pursuing a polling solution, we'll see slower updates than we'd like to pricing information of symbols. In the non-functional requirements, we indicated we wanted a reasonably short SLA to update clients about symbol prices (under 200ms), and the only way we'd guarantee that with this solution is if we poll data every 200ms, which is unreasonable.
    

For a design like this, we can rule out polling the exchange directly as a viable option.

Polling

### 

Good Solution: Polling Internal Cache

##### Approach

This solution still involves polling for price information, but we're polling a symbol service that performs a key-value look-up on an internal cache that is kept up-to-date by a symbol price processor that is listening to prices on the exchange.

This approach prevents excess connections to the exchange by "proxying" it with a service that listens and records the most essential detail: the symbol price. This price is then made available to clients of Robinhood via polling.

##### Challenges

This approach is certainly an improvement, but is still subject to some issues. Clients still indiscriminately poll, even if the price has not changed, leading to some wasted HTTP traffic. Additionally, this approach is a slow way to get price updates; the polling interval dictates the worst-case SLA for a price update propagating to the client. Can we do better?

Polling Internal Cache

### 

Great Solution: Server Sent Event (SSE) Price Updates

##### Approach

A great approach here involves Server Sent Events (SSE). SSE is a persistent connection (similar to websockets), but it is unidirectional and goes over HTTP instead of a separate protocol. For this example, the client isn't sending us data, so SSE is a superior choice to websockets. For more details on reasoning through the websocket vs. SSE trade-off analysis, feel free to reference our [FB Live Comments write-up](https://www.hellointerview.com/learn/system-design/problem-breakdowns/fb-live-comments#2-viewers-can-see-all-comments-in-near-real-time-as-they-are-posted).

###### Pattern: Real-time Updates

Real-time stock price updates are a perfect example of the real-time updates pattern. Here we use Server Sent Events (SSE) to establish persistent connections that allow our servers to push live price changes to clients instantly. This approach handles the networking fundamentals of real-time communication while ensuring users see current market prices without the inefficiency of constant polling.

[Learn This Pattern](/learn/system-design/patterns/realtime-updates)

This approach involves re-working our API to instead have a /subscribe POST request, with a body containing a list of symbols we want to subscribe to. Our backend can then setup a SSE connection between the client and a symbol service, and send the client an initial list of symbol prices. This initial list of prices is serviced by a cache that is kept up-to-date by a processor that is listening to the exchange. Additionally, that processor is sending our symbol service those prices so that the symbol service can send that data to clients that have subscribed to price updates for different symbols.

##### Challenges

Adding SSE introduces challenges, mainly involving maintaining a connection between client and server. The load balancer will need to be configured to support "sticky sessions" so that a user and server can maintain a connection to promote data transfer. Additionally, a persistent connection means we have to consider how disconnects / reconnects work. Finally, we need to consider how we route user connections and symbol data. Several of these details are covered later in our deep dive sections, so stay tuned.

SSE

### 2) Users can manage orders for stocks

The second requirement of Robinhood is allowing users to manage orders for stocks. Users should be able to create orders (limit or market), cancel outstanding orders, and list user orders.

Let's consider our options for creating and cancelling orders via the exchange.

### 

Bad Solution: Send Orders Directly to Exchange

##### Approach

This solution involves directly interacting with the exchange to submit orders. Any orders issued by the client are directly submitted to the exchange.

##### Challenges

While this is a "mainline" way to submit orders that cuts out any incurred latency from a backend proxying the exchange, it can lead to large number of exchange clients and concurrent requests, which will be very expensive. Additionally, there's no clear path for the client to check status of an order, outside of polling the exchange or directly listening to trade feeds, both of which aren't viable solutions. Finally, the client is exclusively responsible for tracking orders. This isn't great, as we can't consider the client's storage to be reliable; the user might uninstall the app or the phone hardware might fail.

Let's consider other solutions.

Send Direct

### 

Good Solution: Send Orders to Dispatch Service via Queue

##### Approach

This solution involves sending orders to an order service, which enqueues them for an order dispatch service. This soluton avoids excess exchange clients by proxying the exchange order execution with the order dispatch service. This service can bear the responsibility of efficient exchange communication. This service sends orders to this dispatch service via a queue. The queue prevents the dispatch service from being overloaded, and the queue volume can serve as a metric that the dispatch service could elastically scale off of.

##### Challenges

This approach is on the right track as it proxies the exchange and allows a path for elastic scalability in the face of increased order load (e.g. bursts in trading traffic). However, this approach breaks down when we consider our tight order SLA (under 200ms as a goal).

If we consider moments of high queue load, perhaps during high trading traffic and before the order dispatch service has scaled up, orders might take a while to be dispatched to the exchange, which could violate our goal SLA. In particular sensitive moments of trading, this can be really bad for users. Imagine a user who wants to quickly order stocks or quickly cancel an outstanding order. It would be unacceptable for them to be left waiting for our dispatcher to eventually handle their order, or for our service to start more machines up to scale up given increased queue load.

What other options do we have?

Dispatch Via Queue

### 

Great Solution: Order Gateway

##### Approach

This approach involves sending our orders directly from the order service to an order dispatch gateway. The gateway would enable external internet communication with the exchange via the order service. The gateway would make the requests to the exchange appear as if they were originating from a small set of IPs.

For this approach, our gateway would be an [AWS NAT gateway](https://docs.aws.amazon.com/vpc/latest/userguide/vpc-nat-gateway.html) which would allow for our order services to make requests to the exchange but then appear under a single or small number of IPs ([elastic IPs](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/elastic-ip-addresses-eip.html), in AWS terms).

Given that the gateway is managing outbound requests, this approach relies on the order service that is accepting requests from the client to play a role in actually managing orders. This service will run business logic to manage orders and will scale up / down as necessary given order volume. Given this search is being routed to from clients, we might make the auto-scaling criterion for this service quite sensitive (e.g. auto-scale when average 50% CPU usage is hit across the fleet) or we might over-provision this service to absorb trading spikes.

##### Challenges

This approach requires our order service to do more to manage orders, meaning it will need to be written in a way that is both efficient for client interaction and efficient for exchange interaction (e.g. potentially batching orders together).

Order Gateway

Now that we know how we'll dispatch orders to the exchange, we also must consider how we'll store orders on our side for the purposes of exposing them to the user. The user should be able to GET /orders to see all their outstanding orders, so how might we keep data on our side to service this request?

In order to track orders, we can stand up an order database that is updated when orders are created or cancelled. The order database will be a relational database to promote consistency via ACID guarantees, and will be partitioned on userId (the ID of the user submitting order changes). This will make querying orders of a user fast, as the query will go to a single node.

The order itself will contain information about the order submitted / cancelled. It will also contain data about the state of the order (pending prior to being submitted to the exchange, submitted when it's submitted to the exchange, etc.). Finally, the order will contain an externalOrderId field, which will be populated by the ID that the exchange responds with when the order service submits the order synchronously.

Additionally, to keep these orders up-to-date, we'll need some sort of trade processor tailing the exchange's trades to see if orders maintained on our side get updated.

Of note, this trade processor would be a fleet of machines that are connected to the exchange in some way to receive price updates. The communication interface here doesn't matter too much. For most systems like this, a client of the exchange like Robinhood would setup a webhook endpoint and register that with the exchange, and the exchange would call the webhook whenever it had updates. In the case of webhooks, the trade processor would have a load balancer and a fleet of machines serving that webhook endpoint. For the sake of simplicity, we visualize the trade processor as a single square on our flowchart.

High Level Design

You might be wondering how we concretely reflect updates based on the exchange's trade feed. Stay tuned, as we'll dive into this in one of our deep dive sections.

[Potential Deep Dives](https://www.hellointerview.com/learn/system-design/in-a-hurry/delivery#deep-dives-10-minutes)
--------------------------------------------------------------------------------------------------------------------

### 1) How can the system scale up live price updates?

It's worth considering how the system will scale live price updates. If many users are subscribing to price updates from several stocks, the system will need to ensure that price updates are successfully propagated to the user via SSE.

The main problem we need to solve is: **how do we route symbol price updates to the symbol service servers connected to users who care about those symbol updates?**

To enable this functionality in a scalable way, we can leverage [Redis pub/sub](https://redis.io/docs/latest/develop/interact/pubsub/) to publish / subscribe to price updates. Users can subscribe to price updates via the symbol service and the symbol service can ensure it is subscribed to symbol price updates via Redis for all the symbols the users care about. The new system diagram might look like this now:

Pub/Sub for Price Updates

Want to learn more about Redis? Check out our [Redis deep dive](https://www.hellointerview.com/learn/system-design/deep-dives/redis) for in-depth discussion of the different ways Redis can be used practically in system design interviews.

Let's walk through the full workflow for price updates:

1.  A user subscribes via a symbol service server. The server tracks Symbol -> Set<userId> mapping, so it adds an entry for each symbol the user is subscribed to.
    
2.  The symbol service server is managing subscriptions to Redis pub/sub for channels corresponding to each symbol. It ensures that it has an active subscription for each symbol the user is subscribed to. If it lacks a subscription, it subscribes to the channel for the symbol.
    
3.  When a symbol changes price, that price update is processed by the symbol price processor, which publishes that price update to Redis. Each symbol service server that is subscribed to that symbol's price updates get the price update via subscription. They then fan-out and send that price update to all users who care about that symbol's price updates.
    
4.  If a user unsubscribes from symbols or disconnects (detected via some heartbeat mechanism), the symbol service server will go through each symbol they were subscribed to and removes them from the Set<userId>. If the symbol service server no longer has any users subscribed to a symbol, it can unsubscribe from the Redis channel for that symbol.
    

The above would scale as it would enable our users to evenly distribute load across the symbol service. Additionally, it would be self-regulating in managing what price updates are being propagated to symbol service servers.

### 2) How does the system track order updates?

When digging into the order dispatch flow, it's worth clarifying how we'll ensure our order DB is updated as orders are updated on the exchange.

Firstly, it's not clear from our current design how the trade processor might reflect updates in the orders DB, based off just a trade. There's no efficient way for the trade processor to look-up a trade via the externalOrderId to update a row in the Order table, given that the table is partitioned by userId . This necessitates a separate key-value data store mapping externalOrderId to the (orderId, userId) that is corresponds to. For this key-value store, we could use something like [RocksDB](https://rocksdb.org/). This key-value store would be populated by the order service after an order is submitted to the exchange synchronously.

This new key-value store enables the trade processor to quickly determine whether the trade involved an order from our system, and subsequently look up the order (go to shard via userId -> look up Order via orderId) to update the Order's details. The new system diagram might look like this:

Order update deep dive

### 3) How does the system manage order consistency?

Order consistency is extremely important and worth deep-diving into. Order consistency is defined as orders being stored with consistency on our side and also consistently managed on the exchange side. As we'll get into, fault-tolerance is important for maintaining order consistency.

Before we dig in, we firstly can revisit our order storage mechansim. Our order database is going to be a horizontally partitioned relational database (e.g. Postgres). All order updates will happen on a single node (the partition that the order exists on). All order reads will also occur on a single node, as we'll be partitioning by userId.

When an order is created, the system goes through the following workflow:

1.  Store an order in the order database with pending as the status. _It's important that this is stored first because then we have a record of the client could. If we didn't store this first, then the client could create an order on the exchange, the system could fail, and then our system has no way of knowing there's an outstanding order._
    
2.  Submit the order to the exchange. Get back externalOrderId immediately (the order submission is synchronous).
    
3.  Write externalOrderId to our key-value database and update the order in the order database with status as submitted and externalOrderId as the ID received from the DB.
    
4.  Respond to the client that the order was successful.
    

The above workflow seems very reasonable, but it might break down if failures occur at different parts of the process. Let's consider several failures, and ways we can mitigate these failures if they pose a risk to our consistency:

*   **Failure storing order**: If there's a failure storing the order, we can respond with a failure to the client and stop the workflow.
    
*   **Failure submitting order to exchange**: If there's a failure submitting the order to the exchange, we can mark the order as failed and respond to the client.
    
*   **Failure processing order after exchange submission**: If there's an error updating the database after an exchange submission, we might consider having a "clean-up" job that deals with outstanding, pending orders in the database. Most exchange APIs offer a clientOrderId metadata field when submitting an order (see [E\*TRADE example](https://apisb.etrade.com/docs/api/order/api-order-v1.html#/definitions/PreviewOrderRequest)) so the "clean-up" job can asynchronously query the exchange to see if the order went through via this clientOrderId identifier, and do one of two things: 1) record the externalOrderId if the order did go through, or 2) mark the order as failed if the order didn't go through.
    

Now that we've considered the order flow, let's consider the cancel flow. When an order is cancelled, the system goes through the following workflow:

1.  Update order status to pending\_cancel. _We do this first to enable resolving failed cancels later._
    
2.  Submit the order cancellation to the exchange.
    
3.  Record the order cancellation in the database.
    
4.  Respond to the client that the cancellation was successful.
    

Let's walk through different failures to ensure we are safe from inconsistency:

*   **Failure updating status to pending\_cancel**: If there's a failure updating the order status upfront, we respond with a failure to the client and stop the workflow.
    
*   **Failure cancelling order**: If there's a failure cancelling the order via the exchange, we can respond with a failure to the client and rely on a "clean-up" process to scan pending\_cancel orders (ensure they are cancelled).
    
*   **Failure storing cancelled status in DB**: If there's a failure updating the order status in the DB, we can rely on a "clean-up" process to pending\_cancel orders (ensure they are cancelled, or no-op and just update status to cancelled if they have already been cancelled).
    

Based on the above analysis, we have 1) a clear understanding of the order create and cancel workflows, and 2) identified the need for a "clean-up" background process to ensure our order state becomes consistent in the face of failures at different points in our order / cancel workflows. Below is the updated system diagram reflecting our changes:

Order consistency deep dive

### Some additional deep dives you might consider

Robinhood, like most fintech systems, is a complex and interesting application, and it's hard to cover every possible consideration in this guide. Here are a few additional deep dives you might consider:

1.  **Excess price updates**: If a set of stocks has a lot of trades or price updates, how might the system handle the load and avoid overwhelming the client? This might be interesting to cover.
    
2.  **Limiting exchange correspondence**: While we certainly covered ways we'd "proxy" the exchange and avoid excess concurrent connections / clients, it might be worthwhile to dive into other ways the system might limit exchange correspondence, while still scaling and serving the userbase (e.g. perhaps considering batching orders into single requests).
    
3.  **Live order updates**: It might be worthwile to dive into how the system would propagate order updates to the user in real time (e.g. if the user is looking at orders in the app, they see their orders get filled in real time if they're waiting on the exchange).
    
4.  **Historical price / portfolio value data**: In this design, we didn't focus on historical price / portfolio data at all, but some interviewers might consider this a requirement. It's worthwhile to ponder how a system would enable showing historical price data (over different time windows) and historical user portfolio value.
    

[What is Expected at Each Level?](https://www.hellointerview.com/blog/the-system-design-interview-what-is-expected-at-each-level)
---------------------------------------------------------------------------------------------------------------------------------

Ok, that was a lot. You may be thinking, "how much of that is actually required from me in an interview?" Letâ€™s break it down.

### Mid-level

**Breadth vs. Depth:** A mid-level candidate will be mostly focused on breadth (80% vs 20%). You should be able to craft a high-level design that meets the functional requirements you've defined, but many of the components will be abstractions with which you only have surface-level familiarity.

**Probing the Basics:** Your interviewer will spend some time probing the basics to confirm that you know what each component in your system does. For example, if you add an API Gateway, expect that they may ask you what it does and how it works (at a high level). In short, the interviewer is not taking anything for granted with respect to your knowledge.

**Mixture of Driving and Taking the Backseat:** You should drive the early stages of the interview in particular, but the interviewer doesnâ€™t expect that you are able to proactively recognize problems in your design with high precision. Because of this, itâ€™s reasonable that they will take over and drive the later stages of the interview while probing your design.

**The Bar for Robinhood:** For this question, an E4 candidate will have clearly defined the API endpoints and data model, landed on a high-level design that is functional for price updates and ordering. I don't expect candidates to know in-depth information about specific technologies, but the candidate should converge on ideas involving efficient price update propagation and consistent order management. I also expect the candidate to know effective ways of proxying the exchange to avoid excess connections / clients.

### Senior

**Depth of Expertise**: As a senior candidate, expectations shift towards more in-depth knowledge â€” about 60% breadth and 40% depth. This means you should be able to go into technical details in areas where you have hands-on experience. It's crucial that you demonstrate a deep understanding of key concepts and technologies relevant to the task at hand.

**Advanced System Design**: You should be familiar with advanced system design principles (different technologies, their use-cases, how they fit together). Your ability to navigate these advanced topics with confidence and clarity is key.

**Articulating Architectural Decisions**: You should be able to clearly articulate the pros and cons of different architectural choices, especially how they impact scalability, performance, and maintainability. You justify your decisions and explain the trade-offs involved in your design choices.

**Problem-Solving and Proactivity**: You should demonstrate strong problem-solving skills and a proactive approach. This includes anticipating potential challenges in your designs and suggesting improvements. You need to be adept at identifying and addressing bottlenecks, optimizing performance, and ensuring system reliability.

**The Bar for Robinhood:** For this question, E5 candidates are expected to quickly go through the initial high-level design so that they can spend time discussing, in detail, how to handle real-time price propagation and consistent orders. I expect the candidate to design a reasonable, scalable solution for live prices, and I expect the candidate to design a good order workflow with some mindfulness of consistency / fault tolerance.

### Staff+

**Emphasis on Depth**: As a staff+ candidate, the expectation is a deep dive into the nuances of system design â€” I'm looking for about 40% breadth and 60% depth in your understanding. This level is all about demonstrating that, while you may not have solved this particular problem before, you have solved enough problems in the real world to be able to confidently design a solution backed by your experience.

You should know which technologies to use, not just in theory but in practice, and be able to draw from your past experiences to explain how theyâ€™d be applied to solve specific problems effectively. The interviewer knows you know the small stuff (REST API, data normalization, etc.) so you can breeze through that at a high level so you have time to get into what is interesting.

**High Degree of Proactivity**: At this level, an exceptional degree of proactivity is expected. You should be able to identify and solve issues independently, demonstrating a strong ability to recognize and address the core challenges in system design. This involves not just responding to problems as they arise but anticipating them and implementing preemptive solutions. Your interviewer should intervene only to focus, not to steer.

**Practical Application of Technology**: You should be well-versed in the practical application of various technologies. Your experience should guide the conversation, showing a clear understanding of how different tools and systems can be configured in real-world scenarios to meet specific requirements.

**Complex Problem-Solving and Decision-Making**: Your problem-solving skills should be top-notch. This means not only being able to tackle complex technical challenges but also making informed decisions that consider various factors such as scalability, performance, reliability, and maintenance.

**Advanced System Design and Scalability**: Your approach to system design should be advanced, focusing on scalability and reliability, especially under high load conditions. This includes a thorough understanding of distributed systems, load balancing, caching strategies, and other advanced concepts necessary for building robust, scalable systems.

**The Bar for Robinhood:** For a staff-level candidate, expectations are high regarding the depth and quality of solutions, especially for the complex scenarios discussed earlier. Exceptional candidates delve deeply into each of the topics mentioned above and may even steer the conversation in a different direction, focusing extensively on a topic they find particularly interesting or relevant. They are also expected to possess a solid understanding of the trade-offs between various solutions and to be able to articulate them clearly, treating the interviewer as a peer.

---

## ğŸ“‹ æ ¸å¿ƒæ€»ç»“ / Core Summary

### 1. Functional Requirements / åŠŸèƒ½éœ€æ±‚

**Core Requirements / æ ¸å¿ƒéœ€æ±‚:**
1. **Users can see live prices of stocks / ç”¨æˆ·å¯ä»¥çœ‹åˆ°è‚¡ç¥¨çš„å®æ—¶ä»·æ ¼**
   - æ”¯æŒæŸ¥çœ‹ä¸€ä¸ªæˆ–å¤šä¸ªè‚¡ç¥¨çš„å®æ—¶ä»·æ ¼æ›´æ–°

2. **Users can manage orders for stocks / ç”¨æˆ·ç®¡ç†è‚¡ç¥¨è®¢å•**
   - åˆ›å»ºè®¢å•ï¼ˆmarket order / limit orderï¼‰
   - å–æ¶ˆè®¢å•
   - æŸ¥çœ‹è®¢å•åˆ—è¡¨

### 2. Non-Functional Requirements / éåŠŸèƒ½éœ€æ±‚

**Core Requirements / æ ¸å¿ƒéœ€æ±‚:**
1. **High Consistency / é«˜ä¸€è‡´æ€§**: è®¢å•ç®¡ç†éœ€è¦é«˜ä¸€è‡´æ€§ï¼Œç”¨æˆ·åœ¨è¿›è¡Œäº¤æ˜“æ—¶å¿…é¡»çœ‹åˆ°æœ€æ–°çš„è®¢å•ä¿¡æ¯
2. **High Scalability / é«˜å¯æ‰©å±•æ€§**: æ”¯æŒ20Mæ—¥æ´»ç”¨æˆ·ï¼Œå¹³å‡æ¯å¤©5ç¬”äº¤æ˜“ï¼Œæ•°åƒä¸ªäº¤æ˜“ç¬¦å·
3. **Low Latency / ä½å»¶è¿Ÿ**: ä»·æ ¼æ›´æ–°å’Œè®¢å•æäº¤çš„å»¶è¿Ÿéœ€ä½äº200ms
4. **Minimize Exchange Connections / æœ€å°åŒ–äº¤æ˜“æ‰€è¿æ¥**: å‡å°‘ä¸å¤–éƒ¨äº¤æ˜“æ‰€APIçš„æ´»è·ƒå®¢æˆ·ç«¯è¿æ¥æ•°ï¼ˆè¿æ¥æˆæœ¬é«˜ï¼‰

### 3. Core Entities / æ ¸å¿ƒå®ä½“

1. **User / ç”¨æˆ·**: ç³»ç»Ÿç”¨æˆ·
2. **Symbol / äº¤æ˜“ç¬¦å·**: è‚¡ç¥¨æ ‡è¯†ç¬¦ï¼ˆå¦‚META, AAPLï¼‰
3. **Order / è®¢å•**: ç”¨æˆ·åˆ›å»ºçš„ä¹°å…¥æˆ–å–å‡ºè®¢å•

### 4. API Design / APIè®¾è®¡

- `GET /symbol/:name` - è·å–è‚¡ç¥¨ä¿¡æ¯å’Œä»·æ ¼æ•°æ®
- `POST /order` - åˆ›å»ºè®¢å•
  - Request: `{position: "buy", symbol: "META", priceInCents: 52210, numShares: 10}`
  - ä½¿ç”¨ `priceInCents` è€Œé `price` é¿å…æµ®ç‚¹æ•°ç²¾åº¦é—®é¢˜
- `DELETE /order/:id` - å–æ¶ˆè®¢å•
- `GET /orders` - è·å–ç”¨æˆ·è®¢å•åˆ—è¡¨ï¼ˆåˆ†é¡µï¼‰
- `POST /subscribe` - è®¢é˜…ä»·æ ¼æ›´æ–°ï¼ˆSSEè¿æ¥ï¼‰

**å®‰å…¨è®¾è®¡**: ç”¨æˆ·ä¿¡æ¯é€šè¿‡headerä¼ é€’ï¼ˆsession tokenæˆ–JWTï¼‰ï¼Œè€Œérequest body

### 5. High-Level Design / é«˜å±‚è®¾è®¡

#### 5.1 æ»¡è¶³åŠŸèƒ½éœ€æ±‚1: Users can see live prices of stocks

**é—®é¢˜**: å¦‚ä½•é«˜æ•ˆåœ°å‘ç”¨æˆ·æ¨é€å®æ—¶è‚¡ç¥¨ä»·æ ¼æ›´æ–°ï¼Ÿ

**è§£å†³æ–¹æ¡ˆå¯¹æ¯”:**

| Solution | Approach | è§£å†³çš„é—®é¢˜ | Challenges / æŒ‘æˆ˜ | Tradeoff |
|----------|----------|-----------|------------------|----------|
| **Bad: Polling Exchange Directly** | å®¢æˆ·ç«¯ç›´æ¥è½®è¯¢äº¤æ˜“æ‰€API | - | â€¢ **å†—ä½™çš„äº¤æ˜“æ‰€è°ƒç”¨**: å¤§é‡å®¢æˆ·ç«¯è¯·æ±‚ç›¸åŒæ•°æ®ï¼Œæµªè´¹èµ„æºï¼ˆå¦‚5000ä¸ªå®¢æˆ·ç«¯åŒæ—¶è¯·æ±‚ç›¸åŒä»·æ ¼ï¼‰<br>â€¢ **æ›´æ–°å»¶è¿Ÿ**: æ— æ³•æ»¡è¶³200ms SLAï¼Œé™¤éæ¯200msè½®è¯¢ä¸€æ¬¡ï¼ˆä¸ç°å®ï¼‰ | ç®€å•ä½†ä¸å…·å¤‡å¯æ‰©å±•æ€§ |
| **Good: Polling Internal Cache** | å®¢æˆ·ç«¯è½®è¯¢å†…éƒ¨ç¼“å­˜ï¼ˆç”±Symbol Price Processorä»äº¤æ˜“æ‰€æ›´æ–°ï¼‰ | â€¢ å‡å°‘äº¤æ˜“æ‰€è¿æ¥æ•°ï¼ˆé€šè¿‡ä»£ç†æœåŠ¡ï¼‰<br>â€¢ é™ä½äº¤æ˜“æ‰€è°ƒç”¨é¢‘ç‡ | â€¢ **ä»æœ‰è½®è¯¢å¼€é”€**: å³ä½¿ä»·æ ¼æœªå˜ï¼Œå®¢æˆ·ç«¯ä»åœ¨è½®è¯¢ï¼Œæµªè´¹HTTPæµé‡<br>â€¢ **æ›´æ–°å»¶è¿Ÿ**: è½®è¯¢é—´éš”å†³å®šæœ€å·®æƒ…å†µä¸‹çš„æ›´æ–°å»¶è¿Ÿ | æ¯”ç›´æ¥è½®è¯¢äº¤æ˜“æ‰€å¥½ï¼Œä½†ä»ä¸å¤Ÿå®æ—¶ |
| **Great: Server Sent Events (SSE)** | ä½¿ç”¨SSEå»ºç«‹æŒä¹…è¿æ¥ï¼ŒæœåŠ¡å™¨æ¨é€ä»·æ ¼æ›´æ–°åˆ°å®¢æˆ·ç«¯ | â€¢ **å®æ—¶æ¨é€**: ä»·æ ¼å˜åŒ–ç«‹å³æ¨é€ç»™å®¢æˆ·ç«¯<br>â€¢ **å‡å°‘è½®è¯¢å¼€é”€**: ä»…åœ¨ä»·æ ¼å˜åŒ–æ—¶å‘é€æ•°æ®<br>â€¢ **å‡å°‘äº¤æ˜“æ‰€è¿æ¥**: é€šè¿‡Symbol Serviceä»£ç† | â€¢ **è¿æ¥ç®¡ç†**: éœ€è¦sticky sessionsï¼Œå¤„ç†æ–­çº¿é‡è¿<br>â€¢ **è·¯ç”±é—®é¢˜**: éœ€è¦å°†ä»·æ ¼æ›´æ–°è·¯ç”±åˆ°æ­£ç¡®çš„æœåŠ¡å™¨å’Œå®¢æˆ·ç«¯ | æœ€ä¼˜æ–¹æ¡ˆï¼Œä½†éœ€è¦å¤„ç†è¿æ¥ç®¡ç†å¤æ‚æ€§ |

**æœ€ç»ˆæ¶æ„**:
- **Symbol Price Processor**: ç›‘å¬äº¤æ˜“æ‰€çš„ä»·æ ¼æ›´æ–°
- **Cache**: å­˜å‚¨æœ€æ–°ä»·æ ¼
- **Symbol Service**: é€šè¿‡SSEå‘å®¢æˆ·ç«¯æ¨é€ä»·æ ¼æ›´æ–°
- **SSEè¿æ¥**: å»ºç«‹æŒä¹…è¿æ¥ï¼Œå®æ—¶æ¨é€

**å®Œæ•´Workflow / å®Œæ•´å·¥ä½œæµç¨‹**:

**Phase 1: ç”¨æˆ·è®¢é˜…æµç¨‹ / User Subscription Flow**
1. ç”¨æˆ·å®¢æˆ·ç«¯å‘èµ· `POST /subscribe` è¯·æ±‚ï¼ŒåŒ…å«è¦è®¢é˜…çš„symbolåˆ—è¡¨ï¼ˆå¦‚["META", "AAPL"]ï¼‰
2. Symbol Serviceæ¥æ”¶è¯·æ±‚ï¼Œå»ºç«‹SSEè¿æ¥ï¼ˆæŒä¹…HTTPè¿æ¥ï¼‰
3. Symbol Serviceç»´æŠ¤å†…å­˜æ˜ å°„ï¼š`Symbol -> Set<userId>`ï¼ˆè·Ÿè¸ªå“ªäº›ç”¨æˆ·è®¢é˜…äº†å“ªäº›symbolï¼‰
4. Symbol Serviceæ£€æŸ¥æ˜¯å¦å·²è®¢é˜…è¯¥symbolçš„Redis channelï¼Œå¦‚æœæ²¡æœ‰åˆ™è®¢é˜…
5. Symbol Serviceä»Cacheè·å–å½“å‰ä»·æ ¼ï¼Œé€šè¿‡SSEå‘é€åˆå§‹ä»·æ ¼æ•°æ®ç»™ç”¨æˆ·
6. SSEè¿æ¥ä¿æŒæ‰“å¼€çŠ¶æ€ï¼Œç­‰å¾…åç»­ä»·æ ¼æ›´æ–°

**Phase 2: ä»·æ ¼æ›´æ–°æµç¨‹ / Price Update Flow**
1. **äº¤æ˜“æ‰€å‘å¸ƒä»·æ ¼æ›´æ–°** â†’ äº¤æ˜“æ‰€trade feedæ¨é€ä»·æ ¼å˜åŒ–ï¼ˆå¦‚METAä»$500å˜ä¸º$501ï¼‰
2. **Symbol Price Processoræ¥æ”¶** â†’ Processorç›‘å¬trade feedï¼Œæ¥æ”¶åˆ°ä»·æ ¼æ›´æ–°äº‹ä»¶
3. **æ›´æ–°Cache** â†’ Processoræ›´æ–°å†…éƒ¨Cacheä¸­çš„æœ€æ–°ä»·æ ¼ï¼ˆKey: "META", Value: 50100 centsï¼‰
4. **å‘å¸ƒåˆ°Redis** â†’ Processorå°†ä»·æ ¼æ›´æ–°å‘å¸ƒåˆ°Redis Pub/Subï¼ˆChannel: "symbol:META", Message: {symbol: "META", price: 50100, timestamp: ...}ï¼‰
5. **Symbol Serviceæ¥æ”¶** â†’ æ‰€æœ‰è®¢é˜…äº†"symbol:META" channelçš„Symbol ServiceæœåŠ¡å™¨æ¥æ”¶Redisæ¶ˆæ¯
6. **æŸ¥æ‰¾è®¢é˜…ç”¨æˆ·** â†’ æ¯ä¸ªSymbol ServiceæœåŠ¡å™¨æŸ¥çœ‹å†…å­˜æ˜ å°„ï¼Œæ‰¾åˆ°æ‰€æœ‰è®¢é˜…äº†"META"çš„ç”¨æˆ·ID
7. **æ¨é€ç»™ç”¨æˆ·** â†’ Symbol ServiceæœåŠ¡å™¨é€šè¿‡å¯¹åº”çš„SSEè¿æ¥ï¼Œå°†ä»·æ ¼æ›´æ–°æ¨é€ç»™æ‰€æœ‰è®¢é˜…ç”¨æˆ·
8. **å®¢æˆ·ç«¯æ›´æ–°** â†’ ç”¨æˆ·å®¢æˆ·ç«¯æ¥æ”¶SSEæ¶ˆæ¯ï¼Œæ›´æ–°UIæ˜¾ç¤ºæœ€æ–°ä»·æ ¼

**Phase 3: è¿æ¥ç®¡ç† / Connection Management**
- **å¿ƒè·³æœºåˆ¶**: å®šæœŸå‘é€keepaliveæ¶ˆæ¯ï¼Œæ£€æµ‹è¿æ¥æ˜¯å¦å­˜æ´»
- **æ–­çº¿é‡è¿**: å®¢æˆ·ç«¯æ£€æµ‹åˆ°æ–­çº¿æ—¶è‡ªåŠ¨é‡è¿ï¼Œé‡æ–°è®¢é˜…
- **æ¸…ç†è®¢é˜…**: ç”¨æˆ·å–æ¶ˆè®¢é˜…æˆ–æ–­å¼€è¿æ¥æ—¶ï¼ŒSymbol Serviceç§»é™¤æ˜ å°„ï¼Œå¦‚æœæ— ç”¨æˆ·è®¢é˜…è¯¥symbolåˆ™å–æ¶ˆRedisè®¢é˜…

**é¢è¯•å™è¿°è¦ç‚¹ / Key Points for Interview**:
- "ç”¨æˆ·è®¢é˜…æ—¶ï¼Œæˆ‘ä»¬å»ºç«‹SSEæŒä¹…è¿æ¥ï¼Œå¹¶ç»´æŠ¤symbolåˆ°ç”¨æˆ·çš„æ˜ å°„"
- "å½“ä»·æ ¼æ›´æ–°æ—¶ï¼ŒProcessoræ›´æ–°Cacheå¹¶å‘å¸ƒåˆ°Redisï¼Œè®¢é˜…çš„æœåŠ¡å™¨æ¥æ”¶åæ¨é€ç»™æ‰€æœ‰ç›¸å…³ç”¨æˆ·"
- "æ•´ä¸ªè¿‡ç¨‹æ˜¯å¼‚æ­¥çš„ï¼Œä»·æ ¼æ›´æ–°åœ¨200mså†…ä»äº¤æ˜“æ‰€åˆ°è¾¾ç”¨æˆ·å®¢æˆ·ç«¯"
- "æˆ‘ä»¬é€šè¿‡Redis Pub/Subå®ç°äº†æ°´å¹³æ‰©å±•ï¼Œå¤šä¸ªSymbol ServiceæœåŠ¡å™¨å¯ä»¥å…±äº«ä»·æ ¼æ›´æ–°"

#### 5.2 æ»¡è¶³åŠŸèƒ½éœ€æ±‚2: Users can manage orders for stocks

**é—®é¢˜**: å¦‚ä½•é«˜æ•ˆåœ°ç®¡ç†è®¢å•æäº¤å’Œå–æ¶ˆï¼Ÿ

**è§£å†³æ–¹æ¡ˆå¯¹æ¯”:**

| Solution | Approach | è§£å†³çš„é—®é¢˜ | Challenges / æŒ‘æˆ˜ | Tradeoff |
|----------|----------|-----------|------------------|----------|
| **Bad: Send Orders Directly to Exchange** | å®¢æˆ·ç«¯ç›´æ¥å‘äº¤æ˜“æ‰€æäº¤è®¢å• | - | â€¢ **å¤§é‡äº¤æ˜“æ‰€å®¢æˆ·ç«¯**: æˆæœ¬é«˜<br>â€¢ **è®¢å•çŠ¶æ€è¿½è¸ªå›°éš¾**: å®¢æˆ·ç«¯éœ€è¦è‡ªå·±è½®è¯¢æˆ–ç›‘å¬trade feed<br>â€¢ **ä¸å¯é **: å®¢æˆ·ç«¯å­˜å‚¨ä¸å¯é ï¼ˆç”¨æˆ·å¯èƒ½å¸è½½appæˆ–è®¾å¤‡æ•…éšœï¼‰ | ç®€å•ä½†ä¸å¯æ‰©å±•ä¸”ä¸å¯é  |
| **Good: Send Orders to Dispatch Service via Queue** | è®¢å•æœåŠ¡ â†’ é˜Ÿåˆ— â†’ è®¢å•åˆ†å‘æœåŠ¡ â†’ äº¤æ˜“æ‰€ | â€¢ å‡å°‘äº¤æ˜“æ‰€è¿æ¥ï¼ˆé€šè¿‡ä»£ç†ï¼‰<br>â€¢ æ”¯æŒå¼¹æ€§æ‰©å±•ï¼ˆæ ¹æ®é˜Ÿåˆ—é•¿åº¦æ‰©å®¹ï¼‰ | â€¢ **å»¶è¿Ÿé—®é¢˜**: é«˜è´Ÿè½½æ—¶é˜Ÿåˆ—å¯èƒ½å¾ˆé•¿ï¼Œæ— æ³•æ»¡è¶³200ms SLA<br>â€¢ **ç”¨æˆ·ä½“éªŒå·®**: ç”¨æˆ·éœ€è¦ç­‰å¾…é˜Ÿåˆ—å¤„ç†ï¼Œåœ¨æ•æ„Ÿäº¤æ˜“æ—¶åˆ»ä¸å¯æ¥å— | å¯æ‰©å±•ä½†æ— æ³•æ»¡è¶³ä½å»¶è¿Ÿè¦æ±‚ |
| **Great: Order Gateway** | è®¢å•æœåŠ¡ â†’ è®¢å•ç½‘å…³ï¼ˆAWS NAT Gatewayï¼‰â†’ äº¤æ˜“æ‰€ | â€¢ **ä½å»¶è¿Ÿ**: ç›´æ¥åŒæ­¥æäº¤åˆ°äº¤æ˜“æ‰€<br>â€¢ **ç»Ÿä¸€IP**: é€šè¿‡NAT Gatewayç»Ÿä¸€å‡ºç«™IP<br>â€¢ **å¯æ‰©å±•**: è®¢å•æœåŠ¡å¯ä»¥å¼¹æ€§æ‰©å±• | â€¢ **æœåŠ¡å¤æ‚æ€§**: è®¢å•æœåŠ¡éœ€è¦åŒæ—¶å¤„ç†å®¢æˆ·ç«¯äº¤äº’å’Œäº¤æ˜“æ‰€äº¤äº’ï¼ˆå¯èƒ½éœ€è¦æ‰¹é‡å¤„ç†è®¢å•ï¼‰ | æœ€ä¼˜æ–¹æ¡ˆï¼Œå¹³è¡¡äº†å»¶è¿Ÿå’Œå¯æ‰©å±•æ€§ |

**è®¢å•å­˜å‚¨**:
- **Order Database**: å…³ç³»å‹æ•°æ®åº“ï¼ˆPostgresï¼‰ï¼ŒæŒ‰`userId`åˆ†åŒºï¼Œä¿è¯ä¸€è‡´æ€§ï¼ˆACIDï¼‰
- **å­—æ®µ**: orderId, userId, symbol, status (pending/submitted/cancelled), externalOrderId, price, numSharesç­‰
- **Trade Processor**: ç›‘å¬äº¤æ˜“æ‰€çš„trade feedï¼Œæ›´æ–°è®¢å•çŠ¶æ€

### 6. Deep Dives / æ·±å…¥æ¢è®¨

#### 6.1 How can the system scale up live price updates? / å¦‚ä½•æ‰©å±•å®æ—¶ä»·æ ¼æ›´æ–°ï¼Ÿ

**é—®é¢˜**: å¦‚ä½•å°†ä»·æ ¼æ›´æ–°è·¯ç”±åˆ°æ­£ç¡®çš„Symbol ServiceæœåŠ¡å™¨å’Œè®¢é˜…ç”¨æˆ·ï¼Ÿ

**è§£å†³æ–¹æ¡ˆå¯¹æ¯”: Redis Pub/Sub vs Kafka**

| ç»´åº¦ / Dimension | Redis Pub/Sub | Kafka Pub/Sub |
|------|--------------|---------------|
| **ååé‡ / Throughput** | â­â­ ä¸­ç­‰ï¼ˆ10k-100k msg/secï¼‰ | â­â­â­ é«˜ï¼ˆ100k-1M+ msg/secï¼‰ |
| **å»¶è¿Ÿ / Latency** | â­â­â­ ä½ï¼ˆ< 1msï¼‰ | â­â­ ä¸­ç­‰ï¼ˆ1-10msï¼‰ |
| **æ¶ˆæ¯æŒä¹…åŒ– / Persistence** | âŒ æ— ï¼ˆsubscriberæ–­å¼€åˆ™ä¸¢å¤±ï¼‰ | âœ… æœ‰ï¼ˆå¯é…ç½®retentionï¼‰ |
| **æ¶ˆæ¯é‡æ”¾ / Replay** | âŒ ä¸æ”¯æŒ | âœ… æ”¯æŒï¼ˆoffsetç®¡ç†ï¼‰ |
| **é›†ç¾¤æ”¯æŒ / Clustering** | âš ï¸ æœ‰é™ï¼ˆPub/Subä¸æ”¯æŒé›†ç¾¤ï¼‰ | âœ… å®Œæ•´æ”¯æŒ |
| **å®ç°å¤æ‚åº¦ / Complexity** | â­â­â­ ç®€å• | â­â­ ä¸­ç­‰ |
| **é€‚ç”¨åœºæ™¯ / Use Case** | ä½å»¶è¿Ÿã€ä¸´æ—¶æ•°æ®ã€å°è§„æ¨¡ | é«˜ååã€éœ€è¦æŒä¹…åŒ–ã€å¤§è§„æ¨¡ |

**æ–¹æ¡ˆé€‰æ‹© / Solution Selection**:

**Redis Pub/Sub é€‚ç”¨åœºæ™¯**:
- ä»·æ ¼æ›´æ–°é¢‘ç‡ä¸æ˜¯ç‰¹åˆ«é«˜ï¼ˆ< 100k updates/secï¼‰
- å…è®¸æ¶ˆæ¯ä¸¢å¤±ï¼ˆä»·æ ¼æ›´æ–°å¾ˆå¿«ï¼Œä¸¢å¤±ä¸€æ¬¡å½±å“ä¸å¤§ï¼‰
- è¿½æ±‚æœ€ä½å»¶è¿Ÿ
- ç³»ç»Ÿè§„æ¨¡ä¸­ç­‰ï¼ˆæ•°åƒä¸ªsymbolï¼Œç™¾ä¸‡çº§ç”¨æˆ·ï¼‰

**Kafka Pub/Sub é€‚ç”¨åœºæ™¯**:
- é«˜ååé‡éœ€æ±‚ï¼ˆ> 100k updates/secï¼Œå¦‚é«˜é¢‘äº¤æ˜“ï¼‰
- éœ€è¦æ¶ˆæ¯æŒä¹…åŒ–å’Œé‡æ”¾ï¼ˆå¦‚è®¢å•çŠ¶æ€æ›´æ–°ï¼‰
- éœ€è¦æ›´å¥½çš„æ°´å¹³æ‰©å±•
- ç³»ç»Ÿè§„æ¨¡å¾ˆå¤§ï¼ˆæ•°ä¸‡ä¸ªsymbolï¼Œåƒä¸‡çº§ç”¨æˆ·ï¼‰

**æ¨èæ–¹æ¡ˆ / Recommended Solution**: 
è€ƒè™‘åˆ°ä»·æ ¼æ›´æ–°éœ€è¦**fan-outæ¨¡å¼**ï¼ˆæ¯ä¸ªSymbol Serviceéƒ½éœ€è¦æ”¶åˆ°ç›¸åŒçš„æ›´æ–°ï¼‰ï¼Œ**Redis Pub/Subæ›´åˆé€‚**ï¼š
1. âœ… å¤©ç„¶æ”¯æŒfan-outï¼Œå®ç°ç®€å•
2. âœ… ä½å»¶è¿Ÿï¼ˆ< 1ms vs Kafkaçš„1-10msï¼‰
3. âœ… å…è®¸æ¶ˆæ¯ä¸¢å¤±ï¼ˆä»·æ ¼æ›´æ–°é¢‘ç‡é«˜ï¼Œä¸¢å¤±ä¸€æ¬¡å½±å“ä¸å¤§ï¼‰
4. âœ… èµ„æºå¼€é”€å°ï¼ˆKafkaéœ€è¦å¤šä¸ªConsumer Groupï¼Œæ¯ä¸ªéƒ½æ¶ˆè´¹æ‰€æœ‰æ¶ˆæ¯ï¼‰
5. âœ… è¿ç»´ç®€å•

**ä½•æ—¶ä½¿ç”¨Kafka**:
- éœ€è¦æ¶ˆæ¯æŒä¹…åŒ–å’Œé‡æ”¾ï¼ˆå¦‚è®¢å•çŠ¶æ€æ›´æ–°ï¼‰
- ç³»ç»Ÿè§„æ¨¡ç‰¹åˆ«å¤§ï¼ˆ> 100k updates/secï¼‰ï¼Œéœ€è¦Kafkaçš„é«˜ååé‡
- éœ€è¦ä¸¥æ ¼çš„å¯é æ€§ä¿è¯ï¼ˆä¸èƒ½ä¸¢å¤±ä»»ä½•æ¶ˆæ¯ï¼‰

**Approach / æ–¹æ³•ï¼ˆRedis Pub/Subï¼‰**:
- Symbol Price Processorå‘å¸ƒä»·æ ¼æ›´æ–°åˆ°Redisï¼ˆChannel: `symbol:{symbol}`ï¼‰
- Symbol ServiceæœåŠ¡å™¨è®¢é˜…ç›¸å…³symbolçš„Redis channel
- å½“ç”¨æˆ·è®¢é˜…æ—¶ï¼ŒSymbol ServiceæœåŠ¡å™¨ç»´æŠ¤`Symbol -> Set<userId>`æ˜ å°„
- ä»·æ ¼æ›´æ–°æ—¶ï¼ŒRediså°†æ¶ˆæ¯å¹¿æ’­ç»™æ‰€æœ‰è®¢é˜…çš„Symbol Serviceï¼ˆfan-outï¼‰ï¼ŒæœåŠ¡å™¨æ¨é€ç»™ç”¨æˆ·

**å¤šå¯¹å¤šå…³ç³»åˆ†æ / Many-to-Many Relationship Analysis**:

**å½“å‰è®¾è®¡ï¼šå¤šå¯¹å¤šå…³ç³»ï¼ˆFan-outæ¨¡å¼ï¼‰**
- å¤šä¸ªSymbol Serviceå¯ä»¥è®¢é˜…åŒä¸€ä¸ªsymbol
- ä¸€ä¸ªSymbol Serviceå¯ä»¥è®¢é˜…å¤šä¸ªsymbol
- æ¯ä¸ªSymbol Serviceç‹¬ç«‹ç»´æŠ¤è‡ªå·±è¿æ¥çš„ç”¨æˆ·çš„æ˜ å°„

**ä¸ºä»€ä¹ˆä¸å»ºè®®Shardingï¼ˆä¸€ä¸ªSymbol Serviceè´Ÿè´£ç‰¹å®šsymbolï¼‰ï¼Ÿ**

| ç»´åº¦ / Dimension | å¤šå¯¹å¤šï¼ˆFan-outï¼‰ | Shardingï¼ˆä¸€å¯¹ä¸€ï¼‰ |
|------|----------------|-------------------|
| **è´Ÿè½½å‡è¡¡ / Load Balancing** | âœ… å¤šä¸ªæœåŠ¡å™¨å…±äº«åŒä¸€symbolçš„è´Ÿè½½ | âŒ çƒ­é—¨symbolå¯èƒ½å¯¼è‡´å•æœåŠ¡å™¨è¿‡è½½ |
| **å®¹é”™æ€§ / Fault Tolerance** | âœ… æŸæœåŠ¡å™¨æŒ‚æ‰ï¼Œå…¶ä»–æœåŠ¡å™¨ä»å¯æœåŠ¡ | âŒ æŸæœåŠ¡å™¨æŒ‚æ‰ï¼Œè¯¥symbolå®Œå…¨ä¸å¯ç”¨ |
| **æ‰©å±•æ€§ / Scalability** | âœ… æ°´å¹³æ‰©å±•ï¼Œæ·»åŠ æœåŠ¡å™¨å³å¯ | âš ï¸ éœ€è¦é‡æ–°shardingï¼Œå¤æ‚ |
| **çƒ­ç‚¹é—®é¢˜ / Hotspot** | âœ… è‡ªåŠ¨åˆ†æ•£åˆ°å¤šæœåŠ¡å™¨ | âŒ çƒ­é—¨symbolé›†ä¸­åˆ°ç‰¹å®šæœåŠ¡å™¨ |
| **å®ç°å¤æ‚åº¦ / Complexity** | â­â­ ä¸­ç­‰ï¼ˆéœ€è¦ç®¡ç†è®¢é˜…å…³ç³»ï¼‰ | â­â­â­ é«˜ï¼ˆéœ€è¦shardingç­–ç•¥å’Œrebalancingï¼‰ |

**å¤šå¯¹å¤šå…³ç³»æ˜¯æ­£å¸¸çš„ / Many-to-Many is Normal**:

**é‡è¦æ¦‚å¿µï¼šFan-out vs Load Sharing**
- **Fan-outæ¨¡å¼**: æ¯ä¸ªSymbol Serviceéƒ½éœ€è¦æ”¶åˆ°ç›¸åŒçš„ä»·æ ¼æ›´æ–°ï¼ˆå› ä¸ºå„è‡ªç»´æŠ¤ä¸åŒçš„ç”¨æˆ·è®¢é˜…ï¼‰
- **Load Sharingæ¨¡å¼**: å¤šä¸ªConsumerå…±äº«å¤„ç†ï¼Œæ¯ä¸ªæ¶ˆæ¯åªè¢«ä¸€ä¸ªConsumerå¤„ç†ï¼ˆä¸é€‚ç”¨äºæ­¤åœºæ™¯ï¼‰

**Kafkaå®ç°Fan-outçš„ä¸¤ç§æ–¹å¼**:

**æ–¹å¼1ï¼šæ¯ä¸ªSymbol Serviceä½¿ç”¨ç‹¬ç«‹çš„Consumer Groupï¼ˆæ¨èï¼‰**
- æ¯ä¸ªSymbol Serviceä½¿ç”¨ä¸åŒçš„Consumer Group IDï¼ˆå¦‚ `symbol-service-1`, `symbol-service-2`ï¼‰
- åŒä¸€ä¸ªtopicçš„æ¯æ¡æ¶ˆæ¯ä¼šè¢«æ‰€æœ‰Consumer Groupæ¶ˆè´¹ï¼ˆfan-outæ•ˆæœï¼‰
- æ¯ä¸ªSymbol Serviceç‹¬ç«‹ç»´æŠ¤offsetï¼Œäº’ä¸å½±å“
- ä¼˜åŠ¿ï¼šå¤©ç„¶fan-outï¼Œç®€å•ç›´è§‚
- åŠ£åŠ¿ï¼šæ¯ä¸ªConsumer Groupéƒ½ä¼šæ¶ˆè´¹æ‰€æœ‰æ¶ˆæ¯ï¼ˆå†…å­˜å’Œå¸¦å®½å¼€é”€ï¼‰

**æ–¹å¼2ï¼šä½¿ç”¨Redis Pub/Subï¼ˆæ›´ç®€å•ï¼‰**
- Redis Pub/Subå¤©ç„¶æ”¯æŒfan-outï¼Œæ‰€æœ‰è®¢é˜…çš„æœåŠ¡å™¨éƒ½ä¼šæ”¶åˆ°æ¶ˆæ¯
- å®ç°æ›´ç®€å•ï¼Œå»¶è¿Ÿæ›´ä½
- ä¸éœ€è¦ç®¡ç†Consumer Group

**ä¸ºä»€ä¹ˆä¸ç”¨åŒä¸€ä¸ªConsumer Groupï¼Ÿ**
- âŒ åŒä¸€ä¸ªConsumer Groupä¸­ï¼Œæ¯æ¡æ¶ˆæ¯åªä¼šè¢«ä¸€ä¸ªConsumerå¤„ç†
- âŒ å¦‚æœSymbol Service-1å¤„ç†äº†AAPLçš„ä»·æ ¼æ›´æ–°ï¼ŒSymbol Service-2å°±æ”¶ä¸åˆ°
- âŒ ä½†Symbol Service-2ä¹Ÿæœ‰è®¢é˜…AAPLçš„ç”¨æˆ·ï¼Œå®ƒä¹Ÿéœ€è¦è¿™ä¸ªæ›´æ–°ï¼
- âœ… å› æ­¤å¿…é¡»ä½¿ç”¨fan-outæ¨¡å¼ï¼ˆæ¯ä¸ªæœåŠ¡å™¨éƒ½æ”¶åˆ°æ‰€æœ‰æ›´æ–°ï¼‰

**Workflow / å·¥ä½œæµç¨‹ï¼ˆä½¿ç”¨Kafka + ç‹¬ç«‹Consumer Groupï¼‰**:
1. ç”¨æˆ·é€šè¿‡Symbol ServiceæœåŠ¡å™¨è®¢é˜…ï¼ŒæœåŠ¡å™¨æ·»åŠ symbolåˆ°æ˜ å°„
2. æ¯ä¸ªSymbol Serviceä½¿ç”¨ç‹¬ç«‹çš„Consumer Groupè®¢é˜…topicï¼ˆå¦‚ `symbol-service-{server-id}`ï¼‰
3. ä»·æ ¼æ›´æ–°æ—¶ï¼ŒProcessorå‘å¸ƒåˆ°Kafkaï¼ˆKey=symbolï¼Œè‡ªåŠ¨partitioningï¼‰
4. **Kafkaå°†æ¶ˆæ¯åˆ†å‘ç»™æ‰€æœ‰Consumer Group**ï¼ˆæ¯ä¸ªSymbol Serviceéƒ½ä¼šæ”¶åˆ°ï¼‰
5. æ¯ä¸ªSymbol Serviceæ¥æ”¶æ¶ˆæ¯åï¼ŒæŸ¥æ‰¾è‡ªå·±ç»´æŠ¤çš„æ˜ å°„ï¼Œæ¨é€ç»™è®¢é˜…è¯¥symbolçš„ç”¨æˆ·
6. ç”¨æˆ·å–æ¶ˆè®¢é˜…æˆ–æ–­å¼€è¿æ¥æ—¶ï¼ŒæœåŠ¡å™¨æ¸…ç†æ˜ å°„

**Workflow / å·¥ä½œæµç¨‹ï¼ˆä½¿ç”¨Redis Pub/Sub - æ›´æ¨èï¼‰**:
1. ç”¨æˆ·é€šè¿‡Symbol ServiceæœåŠ¡å™¨è®¢é˜…ï¼ŒæœåŠ¡å™¨æ·»åŠ symbolåˆ°æ˜ å°„
2. å¦‚æœSymbol Serviceè¿˜æœªè®¢é˜…è¯¥symbolçš„Redis channelï¼Œåˆ™è®¢é˜…
3. ä»·æ ¼æ›´æ–°æ—¶ï¼ŒProcessorå‘å¸ƒåˆ°Redisï¼ˆChannel: `symbol:{symbol}`ï¼‰
4. **Rediså°†æ¶ˆæ¯å¹¿æ’­ç»™æ‰€æœ‰è®¢é˜…çš„Symbol Service**ï¼ˆfan-outï¼‰
5. æ¯ä¸ªSymbol Serviceæ¥æ”¶æ¶ˆæ¯åï¼ŒæŸ¥æ‰¾è‡ªå·±ç»´æŠ¤çš„æ˜ å°„ï¼Œæ¨é€ç»™è®¢é˜…è¯¥symbolçš„ç”¨æˆ·
6. ç”¨æˆ·å–æ¶ˆè®¢é˜…æˆ–æ–­å¼€è¿æ¥æ—¶ï¼ŒæœåŠ¡å™¨æ¸…ç†æ˜ å°„ï¼Œå¦‚æœæ— ç”¨æˆ·è®¢é˜…åˆ™å–æ¶ˆRedisè®¢é˜…

**Redis Pub/Sub vs Kafkaï¼ˆç‹¬ç«‹Consumer Groupï¼‰å¯¹æ¯”**:

| ç»´åº¦ / Dimension | Redis Pub/Sub | Kafkaï¼ˆå¤šConsumer Groupï¼‰ |
|------|--------------|-------------------------|
| **Fan-outæ”¯æŒ / Fan-out** | âœ… åŸç”Ÿæ”¯æŒ | âœ… æ”¯æŒï¼ˆéœ€å¤šä¸ªGroupï¼‰ |
| **æ¶ˆæ¯æŒä¹…åŒ– / Persistence** | âŒ æ—  | âœ… æœ‰ |
| **å»¶è¿Ÿ / Latency** | â­â­â­ ä½ï¼ˆ< 1msï¼‰ | â­â­ ä¸­ç­‰ï¼ˆ1-10msï¼‰ |
| **èµ„æºå¼€é”€ / Resource** | â­â­â­ ä½ | â­ é«˜ï¼ˆæ¯ä¸ªGroupéƒ½æ¶ˆè´¹ï¼‰ |
| **å®ç°å¤æ‚åº¦ / Complexity** | â­â­â­ ç®€å• | â­â­ ä¸­ç­‰ |
| **æ¶ˆæ¯ä¸¢å¤±å®¹å¿ / Loss Tolerance** | âœ… å¯æ¥å—ï¼ˆä»·æ ¼æ›´æ–°å¾ˆå¿«ï¼‰ | âœ… æŒä¹…åŒ–ï¼Œæ›´å¯é  |

**æ¨èæ–¹æ¡ˆ / Recommended Solution**:
å¯¹äºä»·æ ¼æ›´æ–°åœºæ™¯ï¼Œ**Redis Pub/Subæ›´åˆé€‚**ï¼Œå› ä¸ºï¼š
1. âœ… å¤©ç„¶fan-outï¼Œå®ç°ç®€å•
2. âœ… ä½å»¶è¿Ÿï¼ˆ< 1ms vs 1-10msï¼‰
3. âœ… å…è®¸æ¶ˆæ¯ä¸¢å¤±ï¼ˆä»·æ ¼æ›´æ–°é¢‘ç‡é«˜ï¼Œä¸¢å¤±ä¸€æ¬¡å½±å“ä¸å¤§ï¼‰
4. âœ… èµ„æºå¼€é”€å°ï¼ˆKafkaå¤šGroupæ¨¡å¼ä¼šé‡å¤æ¶ˆè´¹ï¼‰
5. âœ… è¿ç»´ç®€å•

**ä½•æ—¶ä½¿ç”¨Kafka**:
- éœ€è¦æ¶ˆæ¯æŒä¹…åŒ–å’Œé‡æ”¾
- éœ€è¦æ›´é«˜å¯é æ€§ï¼ˆä¸èƒ½ä¸¢å¤±æ¶ˆæ¯ï¼‰
- ç³»ç»Ÿè§„æ¨¡ç‰¹åˆ«å¤§ï¼Œéœ€è¦Kafkaçš„å…¶ä»–ç‰¹æ€§

#### 6.2 How does the system track order updates? / ç³»ç»Ÿå¦‚ä½•è¿½è¸ªè®¢å•æ›´æ–°ï¼Ÿ

**é—®é¢˜**: å¦‚ä½•é€šè¿‡`externalOrderId`å¿«é€Ÿæ›´æ–°è®¢å•çŠ¶æ€ï¼ˆOrder DBæŒ‰`userId`åˆ†åŒºï¼‰ï¼Ÿ

**è§£å†³æ–¹æ¡ˆ: Key-Value Store (RocksDB)**

**Approach / æ–¹æ³•**:
- ä½¿ç”¨Key-Value Storeå­˜å‚¨`externalOrderId -> (orderId, userId)`æ˜ å°„
- è®¢å•æäº¤åˆ°äº¤æ˜“æ‰€åï¼ŒOrder Serviceå°†æ˜ å°„å†™å…¥K-V Store
- Trade Processoræ”¶åˆ°trade feedæ—¶ï¼Œé€šè¿‡`externalOrderId`æŸ¥æ‰¾`(orderId, userId)`ï¼Œç„¶åæ›´æ–°Order DB

**ä¼˜åŠ¿**:
- å¿«é€ŸæŸ¥æ‰¾ï¼šO(1)æ—¶é—´å¤æ‚åº¦
- æ”¯æŒé«˜å¹¶å‘å†™å…¥
- æŒä¹…åŒ–å­˜å‚¨

#### 6.3 How does the system manage order consistency? / ç³»ç»Ÿå¦‚ä½•ç®¡ç†è®¢å•ä¸€è‡´æ€§ï¼Ÿ

**é—®é¢˜**: å¦‚ä½•ä¿è¯è®¢å•çŠ¶æ€åœ¨ç³»ç»Ÿæ•…éšœæ—¶çš„ä¸€è‡´æ€§ï¼Ÿ

**è§£å†³æ–¹æ¡ˆ: äº‹åŠ¡æ€§å·¥ä½œæµ + Clean-up Job**

**Order Creation Workflow / è®¢å•åˆ›å»ºæµç¨‹**:
1. åœ¨Order DBä¸­å­˜å‚¨è®¢å•ï¼ˆstatus: `pending`ï¼‰- **å¿…é¡»å…ˆå­˜å‚¨ï¼Œç¡®ä¿æœ‰è®°å½•**
2. æäº¤è®¢å•åˆ°äº¤æ˜“æ‰€ï¼ˆåŒæ­¥ï¼‰ï¼Œè·å¾—`externalOrderId`
3. å†™å…¥K-V Storeï¼ˆexternalOrderId -> orderId, userIdï¼‰å¹¶æ›´æ–°Order DBï¼ˆstatus: `submitted`ï¼‰
4. è¿”å›æˆåŠŸç»™å®¢æˆ·ç«¯

**Failure Handling / å¤±è´¥å¤„ç†**:
- **å­˜å‚¨å¤±è´¥**: è¿”å›å¤±è´¥ç»™å®¢æˆ·ç«¯ï¼Œåœæ­¢æµç¨‹
- **æäº¤åˆ°äº¤æ˜“æ‰€å¤±è´¥**: æ ‡è®°è®¢å•ä¸º`failed`ï¼Œè¿”å›ç»™å®¢æˆ·ç«¯
- **æäº¤åå¤„ç†å¤±è´¥**: Clean-up jobå¤„ç†pendingè®¢å•ï¼Œé€šè¿‡`clientOrderId`æŸ¥è¯¢äº¤æ˜“æ‰€ç¡®è®¤çŠ¶æ€

**Order Cancellation Workflow / è®¢å•å–æ¶ˆæµç¨‹**:
1. æ›´æ–°è®¢å•çŠ¶æ€ä¸º`pending_cancel` - **å…ˆæ›´æ–°çŠ¶æ€ï¼Œä¾¿äºåç»­å¤„ç†å¤±è´¥**
2. å‘äº¤æ˜“æ‰€æäº¤å–æ¶ˆè¯·æ±‚
3. æ›´æ–°Order DBçŠ¶æ€ä¸º`cancelled`
4. è¿”å›æˆåŠŸç»™å®¢æˆ·ç«¯

**Failure Handling / å¤±è´¥å¤„ç†**:
- **æ›´æ–°çŠ¶æ€å¤±è´¥**: è¿”å›å¤±è´¥ï¼Œåœæ­¢æµç¨‹
- **å–æ¶ˆå¤±è´¥**: è¿”å›å¤±è´¥ï¼ŒClean-up jobå¤„ç†`pending_cancel`è®¢å•
- **å­˜å‚¨å–æ¶ˆçŠ¶æ€å¤±è´¥**: Clean-up jobå¤„ç†ï¼Œç¡®è®¤å–æ¶ˆçŠ¶æ€

**Clean-up Job / æ¸…ç†ä»»åŠ¡**:
- åå°ä»»åŠ¡æ‰«æ`pending`å’Œ`pending_cancel`è®¢å•
- é€šè¿‡`clientOrderId`æŸ¥è¯¢äº¤æ˜“æ‰€ç¡®è®¤å®é™…çŠ¶æ€
- æ›´æ–°æ•°æ®åº“çŠ¶æ€ï¼Œä¿è¯æœ€ç»ˆä¸€è‡´æ€§

**Tradeoff**:
- **ä¸€è‡´æ€§ä¿è¯**: é€šè¿‡äº‹åŠ¡å’ŒClean-up jobä¿è¯æœ€ç»ˆä¸€è‡´æ€§
- **å¤æ‚æ€§**: éœ€è¦å¤„ç†å„ç§å¤±è´¥åœºæ™¯ï¼Œå¢åŠ ç³»ç»Ÿå¤æ‚æ€§
- **å»¶è¿Ÿ**: Clean-up jobæ˜¯å¼‚æ­¥çš„ï¼Œå¯èƒ½å­˜åœ¨çŸ­æš‚ä¸ä¸€è‡´

### 7. Transaction Processing Essentials / äº¤æ˜“å¤„ç†è¦ç‚¹æ€»ç»“

é‡‘èç³»ç»Ÿä¸­çš„äº¤æ˜“å¤„ç†ï¼ˆè®¢å•åˆ›å»ºã€å–æ¶ˆã€çŠ¶æ€æ›´æ–°ï¼‰éœ€è¦ä¸¥æ ¼çš„ä¸€è‡´æ€§ä¿è¯ã€‚ä»¥ä¸‹æ˜¯å…³é”®è¦ç‚¹ï¼š

#### 7.1 Consistency / ä¸€è‡´æ€§ä¿è¯

**é—®é¢˜**: å¦‚ä½•ä¿è¯è®¢å•çŠ¶æ€åœ¨ç³»ç»Ÿæ•…éšœæ—¶çš„ä¸€è‡´æ€§ï¼Ÿ

**æ ¸å¿ƒåŸåˆ™ / Core Principles**:
1. **å…ˆå†™æœ¬åœ°ï¼Œå†å†™å¤–éƒ¨ / Write Locally First, Then External**
   - è®¢å•å¿…é¡»å…ˆå†™å…¥æœ¬åœ°æ•°æ®åº“ï¼ˆstatus: `pending`ï¼‰ï¼Œå†æäº¤åˆ°äº¤æ˜“æ‰€
   - å¦‚æœå…ˆæäº¤åˆ°äº¤æ˜“æ‰€åå¤±è´¥ï¼Œç³»ç»Ÿæ— æ³•è¿½è¸ªè®¢å•çŠ¶æ€

2. **çŠ¶æ€æœºç®¡ç† / State Machine Management**
   - å®šä¹‰æ¸…æ™°çš„çŠ¶æ€è½¬æ¢ï¼š`pending` â†’ `submitted` â†’ `filled` / `cancelled`
   - çŠ¶æ€è½¬æ¢å¿…é¡»æ˜¯åŸå­çš„ï¼Œä½¿ç”¨æ•°æ®åº“äº‹åŠ¡ä¿è¯

3. **æœ€ç»ˆä¸€è‡´æ€§ / Eventual Consistency**
   - é€šè¿‡Clean-up jobä¿è¯æœ€ç»ˆä¸€è‡´æ€§
   - æ¥å—çŸ­æš‚çš„ä¸ä¸€è‡´ï¼ˆå¦‚`pending`çŠ¶æ€ï¼‰ï¼Œé€šè¿‡å¼‚æ­¥ä»»åŠ¡ä¿®å¤

**å®ç°æ–¹å¼ / Implementation**:
- **æ•°æ®åº“äº‹åŠ¡ / Database Transactions**: ä½¿ç”¨ACIDäº‹åŠ¡ä¿è¯å•èŠ‚ç‚¹å†…çš„åŸå­æ€§
- **åˆ†å¸ƒå¼äº‹åŠ¡ / Distributed Transactions**: é¿å…ä½¿ç”¨ï¼ˆå¤æ‚ä¸”æ€§èƒ½å·®ï¼‰ï¼Œä½¿ç”¨è¡¥å¿æœºåˆ¶
- **è¡¥å¿æœºåˆ¶ / Compensation**: Clean-up jobå®šæœŸæ£€æŸ¥å¹¶ä¿®å¤ä¸ä¸€è‡´çŠ¶æ€

#### 7.2 Clean-up Job / æ¸…ç†ä»»åŠ¡

**ç›®çš„ / Purpose**: ä¿è¯æœ€ç»ˆä¸€è‡´æ€§ï¼Œå¤„ç†å¤±è´¥çš„äº¤æ˜“çŠ¶æ€

**å·¥ä½œæœºåˆ¶ / How It Works**:
1. **æ‰«æå¼‚å¸¸çŠ¶æ€ / Scan Abnormal States**
   - å®šæœŸæ‰«æ`pending`è®¢å•ï¼ˆå·²åˆ›å»ºä½†æœªç¡®è®¤æäº¤ï¼‰
   - å®šæœŸæ‰«æ`pending_cancel`è®¢å•ï¼ˆå·²è¯·æ±‚å–æ¶ˆä½†æœªç¡®è®¤ï¼‰

2. **æŸ¥è¯¢äº¤æ˜“æ‰€ / Query Exchange**
   - ä½¿ç”¨`clientOrderId`æŸ¥è¯¢äº¤æ˜“æ‰€ç¡®è®¤è®¢å•å®é™…çŠ¶æ€
   - äº¤æ˜“æ‰€APIé€šå¸¸æ”¯æŒé€šè¿‡`clientOrderId`æŸ¥è¯¢è®¢å•çŠ¶æ€

3. **ä¿®å¤çŠ¶æ€ / Fix State**
   - å¦‚æœè®¢å•å·²æäº¤ï¼šæ›´æ–°ä¸º`submitted`ï¼Œè®°å½•`externalOrderId`
   - å¦‚æœè®¢å•æœªæäº¤ï¼šæ ‡è®°ä¸º`failed`
   - å¦‚æœè®¢å•å·²å–æ¶ˆï¼šæ›´æ–°ä¸º`cancelled`
   - å¦‚æœè®¢å•æœªå–æ¶ˆï¼šé‡è¯•å–æ¶ˆæˆ–æ ‡è®°ä¸ºå·²å–æ¶ˆï¼ˆå¦‚æœå·²filledï¼‰

**é…ç½® / Configuration**:
- **æ‰§è¡Œé¢‘ç‡ / Frequency**: æ¯30ç§’-5åˆ†é’Ÿæ‰§è¡Œä¸€æ¬¡ï¼ˆæ ¹æ®SLAè°ƒæ•´ï¼‰
- **è¶…æ—¶è®¾ç½® / Timeout**: è¶…è¿‡ä¸€å®šæ—¶é—´ï¼ˆå¦‚5åˆ†é’Ÿï¼‰çš„`pending`è®¢å•éœ€è¦å¤„ç†
- **é‡è¯•ç­–ç•¥ / Retry Strategy**: æŸ¥è¯¢å¤±è´¥æ—¶ä½¿ç”¨æŒ‡æ•°é€€é¿é‡è¯•

#### 7.3 Idempotency / å¹‚ç­‰æ€§

**é—®é¢˜**: å¦‚ä½•é˜²æ­¢é‡å¤æäº¤å¯¼è‡´çš„é‡å¤è®¢å•ï¼Ÿ

**æ ¸å¿ƒæ¦‚å¿µ / Core Concept**:
- **å¹‚ç­‰æ€§ / Idempotency**: ç›¸åŒçš„è¯·æ±‚æ‰§è¡Œå¤šæ¬¡ï¼Œç»“æœåº”è¯¥ç›¸åŒ
- **Idempotency Key**: å®¢æˆ·ç«¯æä¾›çš„å”¯ä¸€æ ‡è¯†ç¬¦ï¼Œç”¨äºå»é‡

**å®ç°æ–¹å¼ / Implementation**:

**1. å®¢æˆ·ç«¯æä¾›Idempotency Key / Client-Provided Idempotency Key**
```
POST /order
Headers: {
  Idempotency-Key: "uuid-v4-generated-by-client"
}
Request: {
  position: "buy",
  symbol: "META",
  priceInCents: 52210,
  numShares: 10
}
```

**2. æœåŠ¡ç«¯æ£€æŸ¥ / Server-Side Check**
- ä½¿ç”¨`Idempotency-Key`ä½œä¸ºå”¯ä¸€é”®æ£€æŸ¥æ˜¯å¦å·²å¤„ç†
- å¦‚æœå·²å¤„ç†ï¼šè¿”å›ä¹‹å‰çš„ç»“æœï¼ˆç›¸åŒçš„è®¢å•IDå’ŒçŠ¶æ€ï¼‰
- å¦‚æœæœªå¤„ç†ï¼šåˆ›å»ºæ–°è®¢å•ï¼Œè®°å½•`Idempotency-Key`ä¸è®¢å•çš„æ˜ å°„

**3. å­˜å‚¨Idempotency Key / Store Idempotency Key**
- **Redis**: å­˜å‚¨`idempotency-key:{key}` â†’ `{orderId, status, response}`
  - TTL: 24å°æ—¶ï¼ˆè¶³å¤Ÿé•¿ï¼Œè¦†ç›–å®¢æˆ·ç«¯é‡è¯•çª—å£ï¼‰
  - å¿«é€ŸæŸ¥æ‰¾ï¼šO(1)
- **æ•°æ®åº“**: åœ¨Orderè¡¨ä¸­æ·»åŠ `idempotency_key`å­—æ®µï¼ˆå”¯ä¸€ç´¢å¼•ï¼‰
  - æ›´æŒä¹…ï¼Œä½†æŸ¥è¯¢ç¨æ…¢

**æœ€ä½³å®è·µ / Best Practices**:
- **å®¢æˆ·ç«¯ç”Ÿæˆ**: å®¢æˆ·ç«¯ç”ŸæˆUUID v4ä½œä¸ºIdempotency Key
- **æœåŠ¡ç«¯éªŒè¯**: æœåŠ¡ç«¯å¿…é¡»éªŒè¯Keyçš„æ ¼å¼å’Œå”¯ä¸€æ€§
- **å“åº”ç¼“å­˜**: ç¼“å­˜ä¹‹å‰çš„å“åº”ï¼Œç›´æ¥è¿”å›ï¼ˆé¿å…é‡å¤å¤„ç†ï¼‰
- **Keyæ ¼å¼**: ä½¿ç”¨UUID v4ï¼Œç¡®ä¿å…¨å±€å”¯ä¸€

#### 7.4 Double Payment / é‡å¤æ”¯ä»˜é˜²æŠ¤

**é—®é¢˜**: å¦‚ä½•é˜²æ­¢ç”¨æˆ·é‡å¤æäº¤è®¢å•å¯¼è‡´é‡å¤æ‰£æ¬¾ï¼Ÿ

**é˜²æŠ¤æªæ–½ / Protection Measures**:

**1. å¹‚ç­‰æ€§æ£€æŸ¥ / Idempotency Check**
- ä½¿ç”¨Idempotency Keyé˜²æ­¢é‡å¤è¯·æ±‚
- å¦‚æœè¯·æ±‚é‡å¤ï¼Œè¿”å›å·²åˆ›å»ºçš„è®¢å•

**2. çŠ¶æ€æ£€æŸ¥ / State Check**
- æ£€æŸ¥ç”¨æˆ·è´¦æˆ·çŠ¶æ€ï¼ˆä½™é¢ã€æŒä»“é™åˆ¶ç­‰ï¼‰
- æ£€æŸ¥è®¢å•çŠ¶æ€ï¼ˆé¿å…é‡å¤å¤„ç†åŒä¸€è®¢å•ï¼‰

**3. åˆ†å¸ƒå¼é” / Distributed Lock**
- ä½¿ç”¨Redisåˆ†å¸ƒå¼é”é˜²æ­¢å¹¶å‘é‡å¤æäº¤
- Lock Key: `order:user:{userId}:symbol:{symbol}`
- Lock Timeout: 5ç§’ï¼ˆè¶³å¤Ÿå¤„ç†ä¸€ä¸ªè®¢å•ï¼‰
- å¦‚æœè·å–é”å¤±è´¥ï¼Œè¿”å›"å¤„ç†ä¸­"é”™è¯¯

**4. æ•°æ®åº“å”¯ä¸€çº¦æŸ / Database Unique Constraints**
- Orderè¡¨æ·»åŠ å”¯ä¸€ç´¢å¼•ï¼š`(userId, idempotency_key)`
- æ•°æ®åº“å±‚é¢é˜²æ­¢é‡å¤æ’å…¥

**5. ä½™é¢æ£€æŸ¥ / Balance Check**
- ä¸‹å•å‰æ£€æŸ¥è´¦æˆ·ä½™é¢
- ä½¿ç”¨æ•°æ®åº“äº‹åŠ¡é”å®šè´¦æˆ·è®°å½•
- é˜²æ­¢ä½™é¢ä¸è¶³æˆ–é‡å¤æ‰£æ¬¾

#### 7.5 å…¶ä»–å…³é”®è¦ç‚¹ / Other Key Points

**1. Retry Strategy / é‡è¯•ç­–ç•¥**

**ä½•æ—¶é‡è¯• / When to Retry**:
- ç½‘ç»œé”™è¯¯ï¼ˆtimeoutã€connection errorï¼‰
- ä¸´æ—¶æ€§é”™è¯¯ï¼ˆ5xxé”™è¯¯ç ï¼‰
- ä¸é‡è¯•ï¼š4xxé”™è¯¯ï¼ˆå®¢æˆ·ç«¯é”™è¯¯ï¼‰ã€å¹‚ç­‰æ€§å†²çª

**é‡è¯•ç­–ç•¥ / Retry Strategies**:
- **Exponential Backoff / æŒ‡æ•°é€€é¿**: 1s, 2s, 4s, 8s...
- **Jitter / æŠ–åŠ¨**: æ·»åŠ éšæœºå»¶è¿Ÿï¼Œé¿å…é›·ç¾¤æ•ˆåº”
- **Max Retries / æœ€å¤§é‡è¯•æ¬¡æ•°**: 3-5æ¬¡
- **Dead Letter Queue / æ­»ä¿¡é˜Ÿåˆ—**: è¶…è¿‡é‡è¯•æ¬¡æ•°åæ”¾å…¥DLQ

**2. Timeout Handling / è¶…æ—¶å¤„ç†**

**è¶…æ—¶åœºæ™¯ / Timeout Scenarios**:
- å®¢æˆ·ç«¯è¯·æ±‚è¶…æ—¶ï¼ˆ30ç§’ï¼‰
- äº¤æ˜“æ‰€APIè°ƒç”¨è¶…æ—¶ï¼ˆ5-10ç§’ï¼‰
- æ•°æ®åº“æ“ä½œè¶…æ—¶ï¼ˆ5ç§’ï¼‰

**å¤„ç†æ–¹å¼ / Handling**:
- è®¾ç½®åˆç†çš„è¶…æ—¶æ—¶é—´
- è¶…æ—¶åæ ‡è®°ä¸º`pending`ï¼Œç”±Clean-up jobå¤„ç†
- å®¢æˆ·ç«¯å¯ä»¥æŸ¥è¯¢è®¢å•çŠ¶æ€ï¼ˆä½¿ç”¨Idempotency Keyï¼‰

**3. Transaction Isolation / äº‹åŠ¡éš”ç¦»**

**éš”ç¦»çº§åˆ« / Isolation Levels**:
- **Read Committed / è¯»å·²æäº¤**: é»˜è®¤çº§åˆ«ï¼Œé€‚åˆå¤§å¤šæ•°åœºæ™¯
- **Repeatable Read / å¯é‡å¤è¯»**: éœ€è¦æ—¶å¯ä½¿ç”¨ï¼Œé˜²æ­¢å¹»è¯»

**æ³¨æ„äº‹é¡¹ / Considerations**:
- é¿å…é•¿æ—¶é—´äº‹åŠ¡ï¼ˆé”å®šèµ„æºï¼‰
- ä½¿ç”¨ä¹è§‚é”ï¼ˆversionå­—æ®µï¼‰è€Œéæ‚²è§‚é”ï¼ˆSELECT FOR UPDATEï¼‰

**4. Audit Log / å®¡è®¡æ—¥å¿—**

**è®°å½•å†…å®¹ / Log Content**:
- æ‰€æœ‰è®¢å•æ“ä½œï¼ˆåˆ›å»ºã€å–æ¶ˆã€çŠ¶æ€å˜æ›´ï¼‰
- æ“ä½œæ—¶é—´æˆ³ã€æ“ä½œäººã€IPåœ°å€
- è®¢å•è¯¦æƒ…ï¼ˆé‡‘é¢ã€symbolã€æ•°é‡ï¼‰
- æ“ä½œç»“æœï¼ˆæˆåŠŸ/å¤±è´¥ã€é”™è¯¯ä¿¡æ¯ï¼‰

**ç”¨é€” / Usage**:
- æ•…éšœæ’æŸ¥
- åˆè§„å®¡è®¡
- ç”¨æˆ·äº‰è®®å¤„ç†
- æ•°æ®åˆ†æ

**5. Reconciliation / å¯¹è´¦**

**ç›®çš„ / Purpose**: å®šæœŸä¸äº¤æ˜“æ‰€å¯¹è´¦ï¼Œç¡®ä¿æ•°æ®ä¸€è‡´æ€§

**å®ç°æ–¹å¼ / Implementation**:
- **æ¯æ—¥å¯¹è´¦ / Daily Reconciliation**: æ¯æ—¥å‡Œæ™¨å¯¹è´¦å‰ä¸€å¤©çš„æ‰€æœ‰è®¢å•
- **å¯¹è´¦å†…å®¹ / Content**: è®¢å•æ•°é‡ã€é‡‘é¢ã€çŠ¶æ€
- **å¼‚å¸¸å¤„ç† / Exception Handling**: å‘ç°ä¸ä¸€è‡´æ—¶å‘Šè­¦å¹¶äººå·¥å¤„ç†

**6. Rate Limiting / é™æµ**

**ç›®çš„ / Purpose**: é˜²æ­¢æ¶æ„è¯·æ±‚å’Œç³»ç»Ÿè¿‡è½½

**å®ç°æ–¹å¼ / Implementation**:
- **ç”¨æˆ·çº§åˆ« / Per User**: æ¯ä¸ªç”¨æˆ·æ¯ç§’æœ€å¤š10ä¸ªè®¢å•
- **Symbolçº§åˆ« / Per Symbol**: çƒ­é—¨symbolå•ç‹¬é™æµ
- **å…¨å±€é™æµ / Global**: ç³»ç»Ÿæ€»TPSé™åˆ¶

**ç®—æ³• / Algorithm**:
- Token Bucket / ä»¤ç‰Œæ¡¶
- Sliding Window / æ»‘åŠ¨çª—å£
- åˆ†å¸ƒå¼é™æµï¼šä½¿ç”¨Rediså®ç°

#### 7.6 é¢è¯•è¦ç‚¹æ€»ç»“ / Interview Key Points

**å¿…é¡»æŒæ¡çš„æ¦‚å¿µ / Must-Know Concepts**:
1. âœ… **Idempotency Key**: é˜²æ­¢é‡å¤è¯·æ±‚çš„æ ¸å¿ƒæœºåˆ¶
2. âœ… **Clean-up Job**: ä¿è¯æœ€ç»ˆä¸€è‡´æ€§çš„å…³é”®ç»„ä»¶
3. âœ… **çŠ¶æ€æœºç®¡ç†**: æ¸…æ™°çš„çŠ¶æ€è½¬æ¢è§„åˆ™
4. âœ… **åˆ†å¸ƒå¼é”**: é˜²æ­¢å¹¶å‘é‡å¤æäº¤
5. âœ… **é‡è¯•ç­–ç•¥**: æŒ‡æ•°é€€é¿ + æ­»ä¿¡é˜Ÿåˆ—
6. âœ… **è¶…æ—¶å¤„ç†**: è¶…æ—¶åæ ‡è®°pendingï¼Œå¼‚æ­¥å¤„ç†

**å¸¸è§é—®é¢˜ / Common Questions**:
- "å¦‚ä½•å¤„ç†è®¢å•æäº¤åˆ°äº¤æ˜“æ‰€åæœåŠ¡å´©æºƒï¼Ÿ" â†’ Clean-up jobæŸ¥è¯¢äº¤æ˜“æ‰€çŠ¶æ€
- "å¦‚ä½•é˜²æ­¢ç”¨æˆ·é‡å¤ç‚¹å‡»å¯¼è‡´é‡å¤è®¢å•ï¼Ÿ" â†’ Idempotency Key + åˆ†å¸ƒå¼é”
- "å¦‚ä½•ä¿è¯è®¢å•çŠ¶æ€ä¸€è‡´æ€§ï¼Ÿ" â†’ çŠ¶æ€æœº + æ•°æ®åº“äº‹åŠ¡ + Clean-up job
- "è®¢å•è¶…æ—¶æ€ä¹ˆåŠï¼Ÿ" â†’ æ ‡è®°pendingï¼ŒClean-up jobå¤„ç†

### 8. Key Takeaways / å…³é”®è¦ç‚¹

1. **å®æ—¶æ•°æ®æ¨é€**: ä½¿ç”¨SSEä¼˜äºè½®è¯¢ï¼Œæä¾›æ›´å¥½çš„å®æ—¶æ€§å’Œèµ„æºæ•ˆç‡
2. **ä»£ç†æ¨¡å¼**: é€šè¿‡å†…éƒ¨æœåŠ¡ä»£ç†å¤–éƒ¨APIï¼ˆäº¤æ˜“æ‰€ï¼‰ï¼Œå‡å°‘è¿æ¥æ•°å’Œæˆæœ¬
3. **æ•°æ®ä¸€è‡´æ€§**: é‡‘èç³»ç»Ÿéœ€è¦é«˜ä¸€è‡´æ€§ï¼Œéœ€è¦ä»”ç»†è®¾è®¡å·¥ä½œæµå’Œå¤±è´¥å¤„ç†
4. **å¯æ‰©å±•æ€§**: ä½¿ç”¨Pub/Subæ¨¡å¼ï¼ˆRedisï¼‰æ”¯æŒå®æ—¶æ›´æ–°çš„æ°´å¹³æ‰©å±•
5. **å­˜å‚¨è®¾è®¡**: æ ¹æ®æŸ¥è¯¢æ¨¡å¼é€‰æ‹©å­˜å‚¨ï¼ˆå…³ç³»å‹DBæŒ‰userIdåˆ†åŒºï¼ŒK-V Storeç”¨äºå¿«é€ŸæŸ¥æ‰¾ï¼‰
6. **å¤±è´¥æ¢å¤**: Clean-up jobæ˜¯ä¿è¯æœ€ç»ˆä¸€è‡´æ€§çš„å…³é”®ç»„ä»¶
7. **å¹‚ç­‰æ€§ä¿è¯**: Idempotency Keyæ˜¯é˜²æ­¢é‡å¤è¯·æ±‚çš„æ ¸å¿ƒæœºåˆ¶
8. **äº¤æ˜“å®‰å…¨**: åˆ†å¸ƒå¼é” + çŠ¶æ€æ£€æŸ¥ + å¹‚ç­‰æ€§æ£€æŸ¥å¤šé‡é˜²æŠ¤

